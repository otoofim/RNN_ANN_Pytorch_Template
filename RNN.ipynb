{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import rarfile, csv\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils\n",
    "from scipy.stats import pearsonr\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import shuffle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import sklearn\n",
    "import skorch\n",
    "import pickle\n",
    "import math\n",
    "from collections import Counter\n",
    "from fastprogress import master_bar, progress_bar\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from skorch.utils import params_for\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "warnings.filterwarnings(action='once')\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "epoch_num = 20\n",
    "learning_rate = 0.00001\n",
    "dropout_p = 0\n",
    "enc_hidden_size = 128\n",
    "dec_hidden_size = 128\n",
    "n_features = len(dataset_encoded_normalized.columns)-1\n",
    "LSTM_layer = 3\n",
    "LSTM_hidden = 512\n",
    "use_cuda = True\n",
    "BATCH_SIZE = 1\n",
    "L2 = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, enc_hidden_size, dec_hidden_size, LSTM_hidden, LSTM_layer, output_size, dropout_p):\n",
    "\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.enc_hidden_size = enc_hidden_size\n",
    "        \n",
    "        self.dec_hidden_size = dec_hidden_size\n",
    "\n",
    "        self.LSTM_hidden_size = LSTM_hidden\n",
    "\n",
    "        self.enc = nn.Linear(input_size , enc_hidden_size).cuda()\n",
    "        self.relu_enc = nn.ReLU().cuda()\n",
    "        \n",
    "        self.enc2 = nn.Linear(enc_hidden_size , 256).cuda()\n",
    "        self.relu_enc2 = nn.ReLU().cuda()\n",
    "\n",
    "        #self.lstm = nn.LSTM(input_size = enc_hidden_size, hidden_size = LSTM_hidden, num_layers = LSTM_layer,\n",
    "        #                    dropout = dropout_p, bidirectional = True).cuda()\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size = 256, hidden_size = LSTM_hidden, num_layers = LSTM_layer,\n",
    "                            dropout = dropout_p, bidirectional = True).cuda()\n",
    "\n",
    "        self.dec2 = nn.Linear( LSTM_hidden * 2 , 256).cuda()\n",
    "        self.relu_dec2 = nn.ReLU().cuda()\n",
    "        \n",
    "        self.dec = nn.Linear(256 , dec_hidden_size).cuda()\n",
    "        self.relu_dec = nn.ReLU().cuda()\n",
    "                \n",
    "        self.output = nn.Linear(dec_hidden_size , output_size).cuda()\n",
    "\n",
    "        self.dropout = nn.Dropout(p = dropout_p).cuda()\n",
    "\n",
    "        self.softmax = nn.LogSoftmax(dim=2).cuda()\n",
    "\n",
    "\n",
    "    def one_step_forward(self, input, hidden):\n",
    "\n",
    "        encoded = self.relu_enc2(self.enc2(self.relu_enc(self.enc(input))))\n",
    "        \n",
    "        lstm_out, hidden_t1 = self.lstm(encoded.unsqueeze(0), hidden)\n",
    "        \n",
    "        dec = self.relu_dec(self.dec(self.relu_dec2(self.dec2(lstm_out))))\n",
    "\n",
    "        if self.training:\n",
    "            dec = self.dropout(dec)\n",
    "\n",
    "        output = self.output(dec)\n",
    "        softmax = self.softmax(output)\n",
    "\n",
    "        return softmax, hidden_t1\n",
    "        \n",
    "\n",
    "    def initHidden(self, batch_size, num_lstm_layers = 1):\n",
    "        return (torch.zeros(2 * num_lstm_layers, batch_size, self.LSTM_hidden_size).to(device=device), torch.zeros(2 * num_lstm_layers, batch_size, self.LSTM_hidden_size).to(device=device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    \n",
    "    def __init__(self, optimizer = torch.optim.Adam, learning_rate = learning_rate, L2 = L2,\n",
    "                                                    dec_hidden_size = dec_hidden_size,\n",
    "                                                    enc_hidden_size = enc_hidden_size,\n",
    "                                                    LSTM_hidden = LSTM_hidden,\n",
    "                                                    LSTM_layer = LSTM_layer,\n",
    "                                                    n_features = n_features,\n",
    "                                                    output_size = output_size,\n",
    "                                                    dropout_p = dropout_p,\n",
    "                                                    criterion = nn.NLLLoss()):\n",
    "        \n",
    "        self.module = RNN(input_size = n_features, dec_hidden_size = dec_hidden_size, enc_hidden_size = enc_hidden_size,\n",
    "          LSTM_hidden = LSTM_hidden, LSTM_layer = LSTM_layer, output_size = output_size, dropout_p = dropout_p)\n",
    "        self.module = self.module.to(device)\n",
    "        self.LSTM_layer = LSTM_layer\n",
    "        self.n_features = n_features\n",
    "        self.criterion = criterion\n",
    "        \n",
    "        self.optimizer_adam = optimizer(self.module.parameters(), lr = learning_rate, weight_decay = L2)\n",
    "        \n",
    "        \n",
    "    def train_step(self, Xi, yi):\n",
    "\n",
    "        loss = None\n",
    "        accuracy = None\n",
    "        \n",
    "        Xi = Xi.reshape(1,-1,self.n_features)\n",
    "        hid = self.module.initHidden(batch_size = 1, num_lstm_layers = self.LSTM_layer)\n",
    "        self.module.zero_grad()\n",
    "        for i in range(Xi.shape[1]):\n",
    "            \n",
    "            output, hid = self.module.one_step_forward(torch.tensor(Xi[:,i,:]).type(torch.FloatTensor).to(device=device), hid)        \n",
    "            \n",
    "        probabilities = torch.exp(output)\n",
    "        _, predicted = torch.max(output.data, 2)\n",
    "        \n",
    "        if not(yi is None):\n",
    "            \n",
    "            correct = (predicted.squeeze(0) == yi.type(torch.LongTensor).to(device=device)).sum()\n",
    "            accuracy = correct\n",
    "            loss = self.get_loss(output, yi)\n",
    "        \n",
    "            if self.module.training:\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer_adam.step()\n",
    "\n",
    "        return {'loss':  loss, 'probabilities': probabilities, 'acc': accuracy}\n",
    "\n",
    "    def infer(self, Xi, yi=None):\n",
    "\n",
    "        self.module.eval()\n",
    "        output = self.train_step(Xi, yi)\n",
    "        self.module.train()\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def get_loss(self, ys_pred, y_true):\n",
    "        \n",
    "        ys_pred = ys_pred.squeeze(0)\n",
    "        y_true = y_true.squeeze(0)\n",
    "       \n",
    "        return self.criterion(ys_pred, y_true.type(torch.LongTensor).to(device = device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "fault_predictor = Trainer()\n",
    "mb = master_bar(range(1, epoch_num))\n",
    "mb2 = master_bar(range(1, epoch_num))\n",
    "mb.names = ['Training Error', 'Validation Error']\n",
    "mb2.names = ['Training acc', 'Validation acc']\n",
    "\n",
    "epoch_tra_acc = {}\n",
    "epoch_tra_error = {}\n",
    "\n",
    "epoch_evl_acc = {}\n",
    "epoch_evl_error = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in mb:\n",
    "    \n",
    "\n",
    "    tra_acc = []\n",
    "    tra_error = []\n",
    "    \n",
    "    evl_acc = []\n",
    "    evl_error = []\n",
    "    \n",
    "    \n",
    "    for j in progress_bar(range(len(X_tra[0:1000])), parent=mb):\n",
    "        \n",
    "        mb.child.comment = f'training'\n",
    "        \n",
    "        stat = fault_predictor.train_step(X_tra[j], y_tra[j])\n",
    "        tra_acc.append(stat['acc'].cpu().detach().numpy())\n",
    "        tra_error.append(stat['loss'].cpu().detach().numpy())\n",
    "        \n",
    "    mb.write(\"### Training ### Epoch:{} loss:{} acc:{}\".format(i , round(np.sum(tra_error)/(len(tra_error)*1.), 5), round(np.sum(tra_acc)/(len(tra_acc)*1.), 5)))\n",
    "    epoch_tra_error[i] = round(np.sum(tra_error)/(len(tra_error)*1.), 5)\n",
    "    epoch_tra_acc[i] = round(np.sum(tra_acc)/(len(tra_acc)*1.), 5)\n",
    "    #graphs_acc = [[epoch_tra_error.keys(), epoch_tra_error.values()],[epoch_evl_error.keys(), epoch_evl_error.values()]]\n",
    "    graphs_acc = [[epoch_tra_error.keys(), epoch_tra_error.values()],[epoch_evl_error.keys(), epoch_evl_error.values()]]\n",
    "    graphs_acc2 = [[epoch_tra_acc.keys(), epoch_tra_acc.values()],[epoch_evl_acc.keys(), epoch_evl_acc.values()]]\n",
    "    mb.update_graph(graphs_acc)\n",
    "    mb2.update_graph(graphs_acc2)\n",
    "    \n",
    "    if (i % 1) == 0:\n",
    "\n",
    "        for k in progress_bar(range(len(X_test)), parent=mb):\n",
    "            \n",
    "            mb.child.comment = f'validation'\n",
    "            \n",
    "            stat = fault_predictor.infer(X_test[k], y_test[k])\n",
    "            evl_acc.append(stat['acc'].cpu().detach().numpy()) \n",
    "            evl_error.append(stat['loss'].cpu().detach().numpy())\n",
    "        mb.write(\"### Validation ### Epoch:{} loss:{} acc:{}\".format(i , round(np.sum(evl_error)/(len(evl_error)*1.), 5), round(np.sum(evl_acc)/(len(evl_acc)*1.), 5)))\n",
    "        \n",
    "        epoch_evl_acc[i] = round(np.sum(evl_acc)/(len(evl_acc)*1.), 5)\n",
    "        epoch_evl_error[i] = round(np.sum(evl_error)/(len(evl_error)*1.), 5)\n",
    "        \n",
    "        #graphs_acc = [[epoch_tra_error.keys(), epoch_tra_error.values()], [epoch_evl_error.keys(), epoch_evl_error.values()]]\n",
    "        graphs_acc = [[epoch_tra_error.keys(), epoch_tra_error.values()],[epoch_evl_error.keys(), epoch_evl_error.values()]]\n",
    "        graphs_acc2 = [[epoch_tra_acc.keys(), epoch_tra_acc.values()],[epoch_evl_acc.keys(), epoch_evl_acc.values()]]\n",
    "        mb.update_graph(graphs_acc)\n",
    "        mb2.update_graph(graphs_acc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\administrator\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "predd = []\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    pred = fault_predictor.infer(X_test[i])\n",
    "    _, predicted = torch.max(pred['probabilities'].squeeze(0), 1)\n",
    "    predd.append(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = classification_report(y_test.astype(int), [predd[i].cpu().detach().numpy() for i in range(len(predd))])\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_conf_mat(conf_arr):\n",
    "    norm_conf = []\n",
    "    for i in conf_arr:\n",
    "        a = 0\n",
    "        tmp_arr = []\n",
    "        a = sum(i, 0)\n",
    "        for j in i:\n",
    "            tmp_arr.append(float(j)/float(a))\n",
    "        norm_conf.append(tmp_arr)\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    plt.clf()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_aspect(1)\n",
    "    res = ax.imshow(np.array(norm_conf), cmap=plt.cm.jet, \n",
    "                    interpolation='nearest')\n",
    "\n",
    "    width, height = conf_arr.shape\n",
    "\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            ax.annotate(str(conf_arr[x][y]), xy=(y, x), \n",
    "                        horizontalalignment='center',\n",
    "                        verticalalignment='center')\n",
    "\n",
    "    cb = fig.colorbar(res)\n",
    "    alphabet = ['RAN:SITE DOWN (2G_3G_4G)', 'RAN:EXT/MAIN FAIL', 'RAN:EXT/DOOR OPEN', 'RAN:EXT/HIGH TEMP', 'RAN:EXT/RECTIFIRE FAIL', 'RAN:EXT/BATTERY_ALARM', 'RAN:PE', 'RAN:CELL DOWN(2G_3G_4G)', 'RAN:EXT/BATTERY_DISCONNECT']\n",
    "    plt.xticks(range(width), alphabet[:width],rotation='vertical')\n",
    "    plt.yticks(range(height), alphabet[:height])\n",
    "    plt.savefig('confusion_matrix.png', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "\n",
    "\n",
    "conf_arr = confusion_matrix(y_test.astype(int), [predd[i].cpu().detach().numpy() for i in range(len(predd))])\n",
    "\n",
    "vis_conf_mat(conf_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(fault_predictor, './model/RNN2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
